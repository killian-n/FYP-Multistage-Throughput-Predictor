{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_FOLDER = \"C:/Users/Killian/Desktop/FYP-Multistage-Throughput-Predictor/Datasets/Final_Outputs/\"\n",
    "IMAGES_OUTPUT_FOLDER = \"C:/Users/Killian/Desktop/FYP-Multistage-Throughput-Predictor/Own Papers/Undergraduate Paper/Images/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(model_name=\"univariate_baseline\", just_preds=False, mb=True):\n",
    "    if just_preds:\n",
    "        predicted = np.load(DATASETS_FOLDER+model_name+\"_predicted_y.npy\")\n",
    "        if mb:\n",
    "            return predicted/1024\n",
    "        return predicted\n",
    "    true = np.squeeze(np.load(DATASETS_FOLDER+model_name+\"_true_y.npy\"))\n",
    "    predicted = np.load(DATASETS_FOLDER+model_name+\"_predicted_y.npy\")\n",
    "    if mb:\n",
    "        return true/1024, predicted/1024\n",
    "    return true, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variance(data):\n",
    "    return np.var(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std(data):\n",
    "    return np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_residuals(true, pred):\n",
    "        residuals = true-pred\n",
    "        return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def time_step_boxplots(residuals=[], model_names=[], title=\"\", xlim=(), savefig_path=\"\", xlab=\"Residuals (Mbps)\",showfliers = True):\n",
    "    df = pd.DataFrame()\n",
    "    for model, residuals in zip(model_names, residuals):\n",
    "        for i in range(residuals.shape[1]):\n",
    "            temp_df = pd.DataFrame()\n",
    "            temp_df[xlab] = residuals[:,i]\n",
    "            temp_df[\"Horizon (seconds)\"] = i+1\n",
    "            temp_df[\"Model\"] = model\n",
    "            df = pd.concat([df, temp_df])\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    if showfliers:\n",
    "        box = sns.boxplot(x=xlab, y=\"Horizon (seconds)\",\n",
    "                    hue=\"Model\",\n",
    "                    data=df, orient=\"h\", whis=(5,95), saturation=1, flierprops={'marker': 'o', 'markersize': 5, 'markerfacecolor': 'pink'})\n",
    "    else:\n",
    "        box = sns.boxplot(x=xlab, y=\"Horizon (seconds)\",\n",
    "            hue=\"Model\",\n",
    "            data=df, orient=\"h\", whis=(5,95), saturation=1, showfliers=False)\n",
    "    if xlim:\n",
    "        box.set_xlim(xlim)\n",
    "    box.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    # box.set_ylabel(\"Horizon (seconds)\")\n",
    "    if savefig_path:\n",
    "        plt.savefig(savefig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show() # Display the plot on the screen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(true, predicted, epsilon=50/1024):\n",
    "    denominator = np.squeeze(true) + epsilon\n",
    "    try:\n",
    "        mape = np.mean(np.abs((np.squeeze(true) - predicted)/denominator))*100\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        mape = \"n/a\"\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ape(true, predicted, epsilon=50/1024):\n",
    "    denominator = np.squeeze(true) + epsilon\n",
    "    try:\n",
    "        ape = np.abs((np.squeeze(true) - predicted)/denominator)*100\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        ape = \"n/a\"\n",
    "    return ape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(true, predicted):\n",
    "    mse = np.mean(np.power(np.squeeze(true)-predicted, 2))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(true, predicted):\n",
    "    mae = np.mean(np.abs(np.squeeze(true)-predicted))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_table(table):\n",
    "    latex_string = \"\\\\begin{table}[!htb]\\n\\\\centering\\n\\\\begin{tabular}{|c|c|c|c|c|c|}\\n\\\\hline\\n{Model} & {Mean Resids (Mbps)} & {Resids std (Mbps)} & {MAPE} & {MSE (Mbps)} & {MAE (Mbps)}\\\\\\\\\\n\\\\hline\\n\"\n",
    "    for row in table:\n",
    "        for i in range(len(row)):\n",
    "            if i == len(row) - 1:\n",
    "                latex_string += str(row[i]) + \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "            else:\n",
    "                latex_string += str(row[i]) + \" & \"\n",
    "    latex_string_end = \"\\\\end{tabular}\\n\\\\label{tab:train_test_dist}\\n\\\\end{table}\"\n",
    "    latex_string = latex_string + latex_string_end\n",
    "    print(latex_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carry_out_analysis(prefix=\"univariate\", title_prefix=\"Univariate\"):\n",
    "    for dataset in [\"low\", \"medium\", \"high\", 1]:\n",
    "        if dataset == 1:\n",
    "            base_true, base_pred = import_data(model_name=\"{}_baseline\".format(prefix))\n",
    "            multiOne_true, multiOne_pred = import_data(model_name=\"{}_multiOne\".format(prefix))\n",
    "            multiAll_true, multiAll_pred = import_data(model_name=\"{}_multiAll\".format(prefix))\n",
    "\n",
    "            # Get Residuals\n",
    "            base_resids = get_ts_residuals(base_true, base_pred)\n",
    "            multiOne_resids = get_ts_residuals(multiOne_true, multiOne_pred)\n",
    "            multiAll_resids = get_ts_residuals(multiAll_true, multiAll_pred)\n",
    "\n",
    "            # Get Absolute Percent Error\n",
    "            base_ape = get_ape(base_true, base_pred)\n",
    "            multiOne_ape = get_ape(multiOne_true, multiOne_pred)\n",
    "            multiAll_ape = get_ape(multiAll_true, multiAll_pred)\n",
    "            \n",
    "            # Boxplot of residuals\n",
    "            time_step_boxplots(residuals=[base_resids, multiOne_resids, multiAll_resids],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Model Performance on All Test Sequences\",\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"{} On All Test Data\".format(title_prefix))\n",
    "            \n",
    "            # Boxplot of Absolute Percent Error\n",
    "            time_step_boxplots(residuals=[base_ape, multiOne_ape, multiAll_ape],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Absolute Percent Error on All Test Sequences\",\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"APE of {} On All Test Data\".format(title_prefix), xlab=\"Absolute Percent Error\")\n",
    "            \n",
    "            # Boxplot of residuals No outliers\n",
    "            time_step_boxplots(residuals=[base_resids, multiOne_resids, multiAll_resids],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Model Performance on All Test Sequences\",\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"{} On All Test Data no Outliers\".format(title_prefix), showfliers = False)\n",
    "            \n",
    "            # Boxplot of Absolute Percent Error no Outliers\n",
    "            time_step_boxplots(residuals=[base_ape, multiOne_ape, multiAll_ape],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Absolute Percent Error on All Test Sequences\",\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"APE of {} On All Test Data no Outliers\".format(title_prefix), xlab=\"Absolute Percent Error\", showfliers = False)\n",
    "\n",
    "\n",
    "            # Standard Dev\n",
    "            base_std = get_std(base_resids)\n",
    "            multiOne_std = get_std(multiOne_resids)\n",
    "            multiAll_std = get_std(multiAll_resids)\n",
    "\n",
    "            # MAPE\n",
    "            base_mape = get_mape(base_true, base_pred)\n",
    "            multiOne_mape = get_mape(multiOne_true, multiOne_pred)\n",
    "            multiAll_mape = get_mape(multiAll_true, multiAll_pred)\n",
    "\n",
    "            # MSE\n",
    "            base_mse = get_mse(base_true, base_pred)\n",
    "            multiOne_mse = get_mse(multiOne_true, multiOne_pred)\n",
    "            multiAll_mse = get_mse(multiAll_true, multiAll_pred)\n",
    "\n",
    "            # MAE\n",
    "            base_mae = get_mae(base_true, base_pred)\n",
    "            multiOne_mae = get_mae(multiOne_true, multiOne_pred)\n",
    "            multiAll_mae = get_mae(multiAll_true, multiAll_pred)\n",
    "\n",
    "            # Table of metrics\n",
    "            table = PrettyTable([\"Model\", \"Mean Resids (Mbps)\", \" Resids std (Mbps)\", \"MAPE\", \"MSE\", \"MAE\"])\n",
    "            table.add_row([\"Baseline\",np.mean(base_resids), base_std, base_mape, base_mse, base_mae])\n",
    "            table.add_row([\"Multistage One\",np.mean(multiOne_resids), multiOne_std, multiOne_mape, multiOne_mse, multiOne_mae])\n",
    "            table.add_row([\"Multistage All\",np.mean(multiAll_resids), multiAll_std, multiAll_mape, multiAll_mse, multiAll_mae])\n",
    "            print(\"Residuals of All Sequences Test Set\")\n",
    "            #print(table)\n",
    "            raw_table = []\n",
    "            raw_table.append([\"Baseline\",round(np.mean(base_resids),3), round(base_std,3), round(base_mape,3), round(base_mse,3), round(base_mae,3)])\n",
    "            raw_table.append([\"Multistage One\",round(np.mean(multiOne_resids),3), round(multiOne_std,3), round(multiOne_mape,3), round(multiOne_mse,3), round(multiOne_mae,3)])\n",
    "            raw_table.append([\"Multistage All\",round(np.mean(multiAll_resids),3), round(multiAll_std,3), round(multiAll_mape,3), round(multiAll_mse,3), round(multiAll_mae,3)])\n",
    "            create_latex_table(raw_table)\n",
    "        else:\n",
    "            base_true, base_pred = import_data(model_name=\"{}_baseline_{}\".format(prefix, dataset))\n",
    "            single_true, single_pred = import_data(model_name=\"{}_multiOne_{}\".format(prefix, dataset))\n",
    "\n",
    "            # Get Residuals\n",
    "            base_resids = get_ts_residuals(base_true, base_pred)\n",
    "            single_resids = get_ts_residuals(single_true, single_pred)\n",
    "\n",
    "            # Get APE\n",
    "            base_ape = get_ape(base_true, base_pred)\n",
    "            single_ape = get_ape(single_true, single_pred)\n",
    "            \n",
    "            # Boxplot of residuals\n",
    "            time_step_boxplots(residuals=[base_resids, single_resids],\n",
    "                                model_names=[\"Baseline\", \"{} Only\".format(dataset)],\n",
    "                                  title=\"Model Performance on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"{} On {} Test Set\".format(title_prefix, dataset))\n",
    "\n",
    "            # Boxplot of APE\n",
    "            time_step_boxplots(residuals=[base_ape, single_ape],\n",
    "                                model_names=[\"Baseline\", \"{} Only\".format(dataset)],\n",
    "                                  title=\"Absolute Percent Error on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"APE of {} On {} Test Set\".format(title_prefix, dataset), xlab=\"Absolute Percent Error\")\n",
    "            \n",
    "            # Boxplot of residuals no Outliers\n",
    "            time_step_boxplots(residuals=[base_resids, single_resids],\n",
    "                                model_names=[\"Baseline\", \"{} Only\".format(dataset)],\n",
    "                                  title=\"Model Performance on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"{} On {} Test Set no Outliers\".format(title_prefix, dataset), showfliers = False)\n",
    "\n",
    "            # Boxplot of APE no Outliers\n",
    "            time_step_boxplots(residuals=[base_ape, single_ape],\n",
    "                                model_names=[\"Baseline\", \"{} Only\".format(dataset)],\n",
    "                                  title=\"Absolute Percent Error on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"APE of {} On {} Test Set no Outliers\".format(title_prefix, dataset), xlab=\"Absolute Percent Error\", showfliers = False)\n",
    "\n",
    "          ###############\n",
    "            multiOne_pred = import_data(model_name=\"{}_multiOne_ms_{}\".format(prefix, dataset), just_preds=True)\n",
    "            multiAll_pred = import_data(model_name=\"{}_multiAll_ms_{}\".format(prefix, dataset), just_preds=True)\n",
    "\n",
    "            #resids\n",
    "            multiOne_resids = get_ts_residuals(single_true, multiOne_pred)\n",
    "            multiAll_resids = get_ts_residuals(single_true, multiAll_pred)\n",
    "\n",
    "            multiOne_ape = get_ape(single_true, multiOne_pred)\n",
    "            multiAll_ape = get_ape(single_true, multiAll_pred)\n",
    "\n",
    "            # Boxplot of residuals\n",
    "            time_step_boxplots(residuals=[base_resids, multiOne_resids, multiAll_resids],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Model Performance on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"MS {} On {} Test Set\".format(title_prefix, dataset))\n",
    "\n",
    "            # Boxplot of APE\n",
    "            time_step_boxplots(residuals=[base_ape, multiOne_ape, multiAll_ape],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Absolute Percent Error on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"MS APE of {} On {} Test Set\".format(title_prefix, dataset), xlab=\"Absolute Percent Error\")\n",
    "            \n",
    "            # Boxplot of residuals no Outliers\n",
    "            time_step_boxplots(residuals=[base_resids, multiOne_resids, multiAll_resids],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Model Performance on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"MS {} On {} Test Set no Outliers\".format(title_prefix, dataset), showfliers = False)\n",
    "\n",
    "            # Boxplot of APE no Outliers\n",
    "            time_step_boxplots(residuals=[base_ape, multiOne_ape, multiAll_ape],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Absolute Percent Error on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"MS APE of {} On {} Test Set no Outliers\".format(title_prefix, dataset), xlab=\"Absolute Percent Error\", showfliers = False)\n",
    "                        # Standard Dev\n",
    "            base_std = get_std(base_resids)\n",
    "            multiOne_std = get_std(multiOne_resids)\n",
    "            multiAll_std = get_std(multiAll_resids)\n",
    "\n",
    "            # MAPE\n",
    "            base_mape = get_mape(base_true, base_pred)\n",
    "            multiOne_mape = get_mape(single_true, multiOne_pred)\n",
    "            multiAll_mape = get_mape(single_true, multiAll_pred)\n",
    "\n",
    "            # MSE\n",
    "            base_mse = get_mse(base_true, base_pred)\n",
    "            multiOne_mse = get_mse(single_true, multiOne_pred)\n",
    "            multiAll_mse = get_mse(single_true, multiAll_pred)\n",
    "\n",
    "            # MAE\n",
    "            base_mae = get_mae(base_true, base_pred)\n",
    "            multiOne_mae = get_mae(single_true, multiOne_pred)\n",
    "            multiAll_mae = get_mae(single_true, multiAll_pred)\n",
    "            \n",
    "            \n",
    "            raw_table = []\n",
    "            raw_table.append([\"Baseline\",round(np.mean(base_resids),3), round(base_std,3), round(base_mape,3), round(base_mse,3), round(base_mae,3)])\n",
    "            raw_table.append([\"Multistage One\",round(np.mean(multiOne_resids),3), round(multiOne_std,3), round(multiOne_mape,3), round(multiOne_mse,3), round(multiOne_mae,3)])\n",
    "            raw_table.append([\"Multistage All\",round(np.mean(multiAll_resids),3), round(multiAll_std,3), round(multiAll_mape,3), round(multiAll_mse,3), round(multiAll_mae,3)])\n",
    "            print(\"\\n================\\nMULTISTAGE\\n===============\\n\")\n",
    "            create_latex_table(raw_table)\n",
    "            print(\"\\n================\\n\")\n",
    "          #####################\n",
    "\n",
    "            # Standard Dev\n",
    "            base_std = get_std(base_resids)\n",
    "            single_std = get_std(single_resids)\n",
    "\n",
    "            # MAPE\n",
    "            base_mape = get_mape(base_true, base_pred)\n",
    "            single_mape = get_mape(single_true, single_pred)\n",
    "\n",
    "            # MSE\n",
    "            base_mse = get_mse(base_true, base_pred)\n",
    "            single_mse = get_mse(single_true, single_pred)\n",
    "\n",
    "            # MAE\n",
    "            base_mae = get_mae(base_true, base_pred)\n",
    "            single_mae = get_mae(single_true, single_pred)\n",
    "\n",
    "            # Table of metrics\n",
    "            table = PrettyTable([\"Model\", \"Mean Resids (Mbps)\", \" Resids std (Mbps)\", \"MAPE\", \"MSE\", \"MAE\"])\n",
    "            table.add_row([\"Baseline\",np.mean(base_resids), base_std, base_mape, base_mse, base_mae])\n",
    "            table.add_row([\"{} Only\".format(dataset),np.mean(single_resids), single_std, single_mape, single_mse, single_mae])\n",
    "            print(\"Residuals of {} Sequences Test Set\".format(dataset))\n",
    "            #print(table)\n",
    "            \n",
    "            # Latex\n",
    "            raw_table = []\n",
    "            raw_table.append([\"Baseline\",round(np.mean(base_resids),3), round(base_std,3), round(base_mape,3), round(base_mse,3), round(base_mae,3)])\n",
    "            raw_table.append([\"{} Only\".format(dataset),round(np.mean(single_resids),3), round(single_std,3), round(single_mape,3), round(single_mse,3), round(single_mae,3)])\n",
    "            create_latex_table(raw_table)\n",
    "\n",
    "    true, pred = import_data(model_name=\"{}_multiOne_classifier\".format(prefix))\n",
    "    true = np.argmax(true, axis=-1)\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    conf_matrix = confusion_matrix(true, pred)\n",
    "    # create a dictionary to map class names\n",
    "    class_names = {0: \"low\", 1: \"medium\", 2: \"high\"}\n",
    "\n",
    "    # map the class names\n",
    "    true_names = [class_names[x] for x in true]\n",
    "    pred_names = [class_names[x] for x in pred]\n",
    "    report = classification_report(true_names, pred_names, labels=[\"low\", \"medium\", \"high\"])\n",
    "    print(\"Classification Report:\\n\",report)\n",
    "    display_conf = ConfusionMatrixDisplay(conf_matrix, display_labels=[\"Low\", \"Medium\", \"High\"])\n",
    "    display_conf.plot(cmap=\"Oranges\")\n",
    "    plt.savefig(IMAGES_OUTPUT_FOLDER+\"{} Confusion Matrix\".format(title_prefix), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(\"constraint_1_5\", \"Size Constraint of 1 and a half MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(\"constraint_3\", \"Constraint 3Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(\"constraint_1_5\", \"Size Constaint 1_5Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(\"H15H5\", \"H15H5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(\"std_all_baseline\")\n",
    "base_balanced = get_ts_residuals(true, pred, False)\n",
    "mape_balanced = get_mape(true, pred)\n",
    "ape_balanced = get_ape(true, pred)\n",
    "\n",
    "print(true[1]-pred[1])\n",
    "true = true/1024\n",
    "pred = pred/1024\n",
    "print(true[1]-pred[1])\n",
    "# true, pred = import_data(\"pca_selected_baseline\")\n",
    "# base = get_ts_residuals(true, pred)\n",
    "# mape = get_mape(true, pred)\n",
    "# ape = get_ape(true, pred)\n",
    "\n",
    "# time_step_boxplots([base, base_balanced], model_names=[\"Baseline\", \"Balanced Baseline\"], title=\"Balanced vs Unbalanced\")\n",
    "# time_step_boxplots([ape, ape_balanced], model_names=[\"Baseline\", \"Balanced Baseline\"], title=\"Balanced vs Unbalanced\", xlab=\"Absolute Percent Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(\"solo_low_all_network\")\n",
    "low = compute_residuals(true, pred)\n",
    "low_ts = get_ts_residuals(true, pred)\n",
    "true, pred = import_data(\"standard_4_all_network_baseline_low\")\n",
    "base_low = compute_residuals(true, pred)\n",
    "base_low_ts = get_ts_residuals(true, pred)\n",
    "generate_boxplot(datasets=[base_low, low], xlab=[\"Baseline\", \"Low Only\"], title=\"Model Performance on Low Test Sequences\", ylim=(-5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplot(datasets=[base_low, low], xlab=[\"Baseline\", \"Low Only\"], title=\"Model Performance on Low Test Sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_boxplots([base_low_ts, low_ts], model_names=[\"Baseline\", \"Low Only\"], xlim=(-5,5), title=\"Model Performance on Low Test Sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_std = get_std(base_low)\n",
    "low_std = get_std(low)\n",
    "table_low = PrettyTable([\"Model\",\"Mean (Mb)\", \"Standard Dev (Mb)\"])\n",
    "table_low.add_row([\"Baseline\", np.mean(base_low_ts), np.std(base_low_ts)])\n",
    "table_low.add_row([\"Low Only Model\", np.mean(low_ts), np.std(low_ts)])\n",
    "print(\"Residuals of Low Sequences Test Set\")\n",
    "print(table_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(\"solo_medium_all_network\")\n",
    "medium = compute_residuals(true, pred)\n",
    "medium_ts = get_ts_residuals(true, pred)\n",
    "true, pred = import_data(\"standard_4_all_network_baseline_medium\")\n",
    "base_medium = compute_residuals(true, pred)\n",
    "base_medium_ts = get_ts_residuals(true, pred)\n",
    "generate_boxplot(datasets=[base_medium, medium], xlab=[\"Baseline\", \"Medium Only\"], title=\"Model Performance on Medium Test Sequences\", ylim=(-25,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_boxplots([base_medium_ts, medium_ts], model_names=[\"Baseline\", \"Medium Only\"], title=\"Model Performance on Medium Test Sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_std = get_std(base_medium_ts)\n",
    "medium_std = get_std(medium_ts)\n",
    "table_medium = PrettyTable([\"Model\",\"Mean (Mb)\", \"Standard Dev (Mb)\"])\n",
    "table_medium.add_row([\"Baseline\",np.mean(base_medium_ts), base_std])\n",
    "table_medium.add_row([\"Medium Only Model\",np.mean(medium_ts), medium_std])\n",
    "print(\"Residuals of Medium Sequences Test Set\")\n",
    "print(table_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(\"solo_high_all_network\")\n",
    "high = compute_residuals(true, pred)\n",
    "high_ts = get_ts_residuals(true, pred)\n",
    "true, pred = import_data(\"standard_4_all_network_baseline_high\")\n",
    "base_high = compute_residuals(true, pred)\n",
    "base_high_ts = get_ts_residuals(true, pred)\n",
    "generate_boxplot(datasets=[base_high, high], xlab=[\"Baseline\", \"High Only\"], title=\"Model Performance on High Test Sequences\", ylim=(-40, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_boxplots([base_high_ts, high_ts], model_names=[\"Baseline\", \"High Only\"], title=\"Model Performance on High Test Sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_std = get_std(base_high_ts)\n",
    "high_std = get_std(high_ts)\n",
    "table_high = PrettyTable([\"Model\",\"Mean (Mb)\", \"Standard Dev (Mb)\"])\n",
    "table_high.add_row([\"Baseline\",np.mean(base_high_ts), base_std])\n",
    "table_high.add_row([\"High Only Model\",np.mean(high_ts), high_std])\n",
    "print(\"Residuals of High Sequences Test Set\")\n",
    "print(table_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(\"standardized_multiOne\")\n",
    "multi_one_ts = get_ts_residuals(true, pred)\n",
    "multi_one_mape = get_mape(true, pred)\n",
    "\n",
    "true, pred = import_data(\"standardized_multiAll\")\n",
    "multi_all_ts = get_ts_residuals(true, pred)\n",
    "multi_all_mape = get_mape(true, pred)\n",
    "\n",
    "true, pred = import_data(\"standard_4_all_network_baseline\")\n",
    "base_ts = get_ts_residuals(true, pred)\n",
    "base_mape = get_mape(true, pred)\n",
    "# generate_boxplot(datasets=[base, multi_one, multi_all], xlab=[\"Baseline\", \"Multistage One\", \"Multistage All\"], title=\"Model Performance on All Test Sequences\")\n",
    "# generate_boxplot(datasets=[base, multi_one], xlab=[\"Baseline\", \"Multistage One\"], title=\"Model Performance on all Test Sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_std = get_std(base_ts)\n",
    "multi_one_std = get_std(multi_one_ts)\n",
    "multi_all_std = get_std(multi_all_ts)\n",
    "table = PrettyTable([\"Model\",\"Mean (Mb)\", \"Standard Dev (Mb)\", \"MAPE\"])\n",
    "table.add_row([\"Baseline\",np.mean(base_ts), base_std, base_mape])\n",
    "table.add_row([\"Multistage One\",np.mean(multi_one_ts), multi_one_std, multi_one_mape])\n",
    "table.add_row([\"Multistage All\",np.mean(multi_all_ts), multi_all_std, multi_all_mape])\n",
    "print(\"Residuals of All Sequences Test Set\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_boxplots([base_ts, multi_one_ts, multi_all_ts], model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"], title=\"Model Performance on All Test Sequences\", xlim=(-80, 200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(\"presentation_2_multiOne\")\n",
    "multi_one_ts = get_ts_residuals(true, pred)\n",
    "multi_one_mape = get_mape(true, pred)\n",
    "\n",
    "true, pred = import_data(\"presentation_2_multiAll\")\n",
    "multi_all_ts = get_ts_residuals(true, pred)\n",
    "multi_all_mape = get_mape(true, pred)\n",
    "\n",
    "true_low, pred_low = import_data(\"standard_4_all_network_baseline_low\")\n",
    "true_low = np.squeeze(true_low)\n",
    "true_medium, pred_medium = import_data(\"standard_4_all_network_baseline_medium\")\n",
    "true_medium = np.squeeze(true_medium)\n",
    "true = np.zeros((len(true_low)+len(true_medium), true_low.shape[1]))\n",
    "pred = np.zeros((len(pred_low)+len(pred_medium), pred_low.shape[1]))\n",
    "\n",
    "\n",
    "true[:len(true_low),:] = true_low\n",
    "true[len(true_low):,:] = true_medium\n",
    "pred[:len(pred_low),:] = pred_low\n",
    "pred[len(pred_low):,:] = pred_medium\n",
    "\n",
    "base_mape = get_mape(true, pred)\n",
    "base_ts = get_ts_residuals(true, pred)\n",
    "time_step_boxplots([base_ts, multi_one_ts, multi_all_ts], model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"], title=\"Model Performance on Med&Low Test Sequences\", xlim=(-50,44))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_std = get_std(base_ts)\n",
    "multi_one_std = get_std(multi_one_ts)\n",
    "multi_all_std = get_std(multi_all_ts)\n",
    "table = PrettyTable([\"Model\",\"Mean (Mb)\", \"Standard Dev (Mb)\", \"MAPE\"])\n",
    "table.add_row([\"Baseline\",np.mean(base), base_std, base_mape])\n",
    "table.add_row([\"Multistage One\",np.mean(multi_one), multi_one_std, multi_one_mape])\n",
    "table.add_row([\"Multistage All\",np.mean(multi_all), multi_all_std, multi_all_mape])\n",
    "print(\"Residuals of Med & Low Sequences Test Set\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Residuals of Low Sequences Test Set\")\n",
    "print(table_low)\n",
    "print(\"==============================================================\\n\")\n",
    "print(\"Residuals of Medium Sequences Test Set\")\n",
    "print(table_medium)\n",
    "print(\"==============================================================\\n\")\n",
    "print(\"Residuals of High Sequences Test Set\")\n",
    "print(table_high)\n",
    "print(\"==============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(\"solo_all_network_classifier\")\n",
    "print(true)\n",
    "print(pred)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "print(pred)\n",
    "conf_matrix = confusion_matrix(true, pred)\n",
    "display_conf = ConfusionMatrixDisplay(conf_matrix, display_labels=[\"Low\", \"Medium\", \"High\"])\n",
    "display_conf.plot(cmap=\"Oranges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(prefix=\"presentation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0f0acd0089a531616946ee2a9708cd6d3e1ac7fcc3f79f44e37592fb92385f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
