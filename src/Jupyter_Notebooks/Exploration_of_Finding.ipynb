{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_FOLDER = \"C:/Users/Killian/Desktop/FYP-Multistage-Throughput-Predictor/Datasets/Final_Outputs/\"\n",
    "IMAGES_OUTPUT_FOLDER = \"C:/Users/Killian/Desktop/Paper V2/Images/\"\n",
    "TEST_FOLDER = \"C:/Users/Killian/Desktop/FYP-Multistage-Throughput-Predictor/Datasets/Testing/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(model_name=\"univariate_baseline\", just_preds=False, mb=True):\n",
    "    if just_preds:\n",
    "        predicted = np.load(DATASETS_FOLDER+model_name+\"_predicted_y.npy\")\n",
    "        if mb:\n",
    "            return predicted/1024\n",
    "        return predicted\n",
    "    true = np.squeeze(np.load(DATASETS_FOLDER+model_name+\"_true_y.npy\"))\n",
    "    predicted = np.load(DATASETS_FOLDER+model_name+\"_predicted_y.npy\")\n",
    "    if mb:\n",
    "        return true/1024, predicted/1024\n",
    "    return true, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variance(data):\n",
    "    return np.var(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std(data):\n",
    "    return np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_residuals(true, pred):\n",
    "        residuals = true-pred\n",
    "        return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def time_step_boxplots(residuals=[], model_names=[], title=\"\", xlim=(), savefig_path=\"\", xlab=\"Residuals (Mbps)\",showfliers = True):\n",
    "    df = pd.DataFrame()\n",
    "    for model, residuals in zip(model_names, residuals):\n",
    "        for i in range(residuals.shape[1]):\n",
    "            temp_df = pd.DataFrame()\n",
    "            temp_df[xlab] = residuals[:,i]\n",
    "            temp_df[\"Horizon (seconds)\"] = i+1\n",
    "            temp_df[\"Model\"] = model\n",
    "            df = pd.concat([df, temp_df])\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    if showfliers:\n",
    "        box = sns.boxplot(x=xlab, y=\"Horizon (seconds)\",\n",
    "                    hue=\"Model\",\n",
    "                    data=df, orient=\"h\", whis=(5,95), saturation=1, flierprops={'marker': 'o', 'markersize': 5, 'markerfacecolor': 'pink'})\n",
    "    else:\n",
    "        box = sns.boxplot(x=xlab, y=\"Horizon (seconds)\",\n",
    "            hue=\"Model\",\n",
    "            data=df, orient=\"h\", whis=(5,95), saturation=1, showfliers=False)\n",
    "    if xlim:\n",
    "        box.set_xlim(xlim)\n",
    "    box.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    # box.set_ylabel(\"Horizon (seconds)\")\n",
    "    if savefig_path:\n",
    "        plt.savefig(savefig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show() # Display the plot on the screen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(true, predicted, epsilon=50/1024):\n",
    "    denominator = np.squeeze(true) + epsilon\n",
    "    try:\n",
    "        mape = np.mean(np.abs((np.squeeze(true) - predicted)/denominator))*100\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        mape = \"n/a\"\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ape(true, predicted, epsilon=50/1024):\n",
    "    denominator = np.squeeze(true) + epsilon\n",
    "    try:\n",
    "        ape = np.abs((np.squeeze(true) - predicted)/denominator)*100\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        ape = \"n/a\"\n",
    "    return ape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(true, predicted):\n",
    "    mse = np.mean(np.power(np.squeeze(true)-predicted, 2))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(true, predicted):\n",
    "    mae = np.mean(np.abs(np.squeeze(true)-predicted))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_table(table):\n",
    "    latex_string = \"\\\\begin{table}[!htb]\\n\\\\centering\\n\\\\begin{tabular}{|c|c|c|c|c|c|}\\n\\\\hline\\n{Model} & {Mean Resids (Mbps)} & {Resids std (Mbps)} & {MAPE} & {MSE (Mbps)} & {MAE (Mbps)}\\\\\\\\\\n\\\\hline\\n\"\n",
    "    for row in table:\n",
    "        for i in range(len(row)):\n",
    "            if i == len(row) - 1:\n",
    "                latex_string += str(row[i]) + \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "            else:\n",
    "                latex_string += str(row[i]) + \" & \"\n",
    "    latex_string_end = \"\\\\end{tabular}\\n\\\\label{tab:train_test_dist}\\n\\\\end{table}\"\n",
    "    latex_string = latex_string + latex_string_end\n",
    "    print(latex_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carry_out_analysis(prefix=\"univariate\", title_prefix=\"Univariate\"):\n",
    "    for dataset in [\"low\", \"medium\", \"high\", 1]:\n",
    "        if dataset == 1:\n",
    "            base_true, base_pred = import_data(model_name=\"{}_baseline\".format(prefix))\n",
    "            multiOne_true, multiOne_pred = import_data(model_name=\"{}_multiOne\".format(prefix))\n",
    "            multiAll_true, multiAll_pred = import_data(model_name=\"{}_multiAll\".format(prefix))\n",
    "\n",
    "            # Get Residuals\n",
    "            base_resids = get_ts_residuals(base_true, base_pred)\n",
    "            multiOne_resids = get_ts_residuals(multiOne_true, multiOne_pred)\n",
    "            multiAll_resids = get_ts_residuals(multiAll_true, multiAll_pred)\n",
    "\n",
    "            # Get Absolute Percent Error\n",
    "            base_ape = get_ape(base_true, base_pred)\n",
    "            multiOne_ape = get_ape(multiOne_true, multiOne_pred)\n",
    "            multiAll_ape = get_ape(multiAll_true, multiAll_pred)\n",
    "            \n",
    "            # Boxplot of residuals\n",
    "            time_step_boxplots(residuals=[base_resids, multiOne_resids, multiAll_resids],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Model Performance on All Test Sequences\",\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"{} On All Test Data\".format(title_prefix))\n",
    "            \n",
    "            # Boxplot of Absolute Percent Error\n",
    "            time_step_boxplots(residuals=[base_ape, multiOne_ape, multiAll_ape],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Absolute Percent Error on All Test Sequences\",\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"APE of {} On All Test Data\".format(title_prefix), xlab=\"Absolute Percent Error\")\n",
    "            \n",
    "            # Boxplot of residuals No outliers\n",
    "            time_step_boxplots(residuals=[base_resids, multiOne_resids, multiAll_resids],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Model Performance on All Test Sequences\",\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"{} On All Test Data no Outliers\".format(title_prefix), showfliers = False)\n",
    "            \n",
    "            # Boxplot of Absolute Percent Error no Outliers\n",
    "            time_step_boxplots(residuals=[base_ape, multiOne_ape, multiAll_ape],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Absolute Percent Error on All Test Sequences\",\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"APE of {} On All Test Data no Outliers\".format(title_prefix), xlab=\"Absolute Percent Error\", showfliers = False)\n",
    "\n",
    "\n",
    "            # Standard Dev\n",
    "            base_std = get_std(base_resids)\n",
    "            multiOne_std = get_std(multiOne_resids)\n",
    "            multiAll_std = get_std(multiAll_resids)\n",
    "\n",
    "            # MAPE\n",
    "            base_mape = get_mape(base_true, base_pred)\n",
    "            multiOne_mape = get_mape(multiOne_true, multiOne_pred)\n",
    "            multiAll_mape = get_mape(multiAll_true, multiAll_pred)\n",
    "\n",
    "            # MSE\n",
    "            base_mse = get_mse(base_true, base_pred)\n",
    "            multiOne_mse = get_mse(multiOne_true, multiOne_pred)\n",
    "            multiAll_mse = get_mse(multiAll_true, multiAll_pred)\n",
    "\n",
    "            # MAE\n",
    "            base_mae = get_mae(base_true, base_pred)\n",
    "            multiOne_mae = get_mae(multiOne_true, multiOne_pred)\n",
    "            multiAll_mae = get_mae(multiAll_true, multiAll_pred)\n",
    "\n",
    "            # Table of metrics\n",
    "            table = PrettyTable([\"Model\", \"Mean Resids (Mbps)\", \" Resids std (Mbps)\", \"MAPE\", \"MSE\", \"MAE\"])\n",
    "            table.add_row([\"Baseline\",np.mean(base_resids), base_std, base_mape, base_mse, base_mae])\n",
    "            table.add_row([\"Multistage One\",np.mean(multiOne_resids), multiOne_std, multiOne_mape, multiOne_mse, multiOne_mae])\n",
    "            table.add_row([\"Multistage All\",np.mean(multiAll_resids), multiAll_std, multiAll_mape, multiAll_mse, multiAll_mae])\n",
    "            print(\"Residuals of All Sequences Test Set\")\n",
    "            #print(table)\n",
    "            raw_table = []\n",
    "            raw_table.append([\"Baseline\",round(np.mean(base_resids),3), round(base_std,3), round(base_mape,3), round(base_mse,3), round(base_mae,3)])\n",
    "            raw_table.append([\"Multistage One\",round(np.mean(multiOne_resids),3), round(multiOne_std,3), round(multiOne_mape,3), round(multiOne_mse,3), round(multiOne_mae,3)])\n",
    "            raw_table.append([\"Multistage All\",round(np.mean(multiAll_resids),3), round(multiAll_std,3), round(multiAll_mape,3), round(multiAll_mse,3), round(multiAll_mae,3)])\n",
    "            create_latex_table(raw_table)\n",
    "        else:\n",
    "            base_true, base_pred = import_data(model_name=\"{}_baseline_{}\".format(prefix, dataset))\n",
    "            single_true, single_pred = import_data(model_name=\"{}_multiOne_{}\".format(prefix, dataset))\n",
    "\n",
    "            # Get Residuals\n",
    "            base_resids = get_ts_residuals(base_true, base_pred)\n",
    "            single_resids = get_ts_residuals(single_true, single_pred)\n",
    "\n",
    "            # Get APE\n",
    "            base_ape = get_ape(base_true, base_pred)\n",
    "            single_ape = get_ape(single_true, single_pred)\n",
    "            \n",
    "            # Boxplot of residuals\n",
    "            time_step_boxplots(residuals=[base_resids, single_resids],\n",
    "                                model_names=[\"Baseline\", \"{} Only\".format(dataset)],\n",
    "                                  title=\"Model Performance on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"{} On {} Test Set\".format(title_prefix, dataset))\n",
    "\n",
    "            # Boxplot of APE\n",
    "            time_step_boxplots(residuals=[base_ape, single_ape],\n",
    "                                model_names=[\"Baseline\", \"{} Only\".format(dataset)],\n",
    "                                  title=\"Absolute Percent Error on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"APE of {} On {} Test Set\".format(title_prefix, dataset), xlab=\"Absolute Percent Error\")\n",
    "            \n",
    "            # Boxplot of residuals no Outliers\n",
    "            time_step_boxplots(residuals=[base_resids, single_resids],\n",
    "                                model_names=[\"Baseline\", \"{} Only\".format(dataset)],\n",
    "                                  title=\"Model Performance on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"{} On {} Test Set no Outliers\".format(title_prefix, dataset), showfliers = False)\n",
    "\n",
    "            # Boxplot of APE no Outliers\n",
    "            time_step_boxplots(residuals=[base_ape, single_ape],\n",
    "                                model_names=[\"Baseline\", \"{} Only\".format(dataset)],\n",
    "                                  title=\"Absolute Percent Error on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"APE of {} On {} Test Set no Outliers\".format(title_prefix, dataset), xlab=\"Absolute Percent Error\", showfliers = False)\n",
    "\n",
    "          ###############\n",
    "            multiOne_pred = import_data(model_name=\"{}_multiOne_ms_{}\".format(prefix, dataset), just_preds=True)\n",
    "            multiAll_pred = import_data(model_name=\"{}_multiAll_ms_{}\".format(prefix, dataset), just_preds=True)\n",
    "\n",
    "            #resids\n",
    "            multiOne_resids = get_ts_residuals(single_true, multiOne_pred)\n",
    "            multiAll_resids = get_ts_residuals(single_true, multiAll_pred)\n",
    "\n",
    "            multiOne_ape = get_ape(single_true, multiOne_pred)\n",
    "            multiAll_ape = get_ape(single_true, multiAll_pred)\n",
    "\n",
    "            # Boxplot of residuals\n",
    "            time_step_boxplots(residuals=[base_resids, multiOne_resids, multiAll_resids],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Model Performance on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"MS {} On {} Test Set\".format(title_prefix, dataset))\n",
    "\n",
    "            # Boxplot of APE\n",
    "            time_step_boxplots(residuals=[base_ape, multiOne_ape, multiAll_ape],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Absolute Percent Error on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"MS APE of {} On {} Test Set\".format(title_prefix, dataset), xlab=\"Absolute Percent Error\")\n",
    "            \n",
    "            # Boxplot of residuals no Outliers\n",
    "            time_step_boxplots(residuals=[base_resids, multiOne_resids, multiAll_resids],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Model Performance on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"MS {} On {} Test Set no Outliers\".format(title_prefix, dataset), showfliers = False)\n",
    "\n",
    "            # Boxplot of APE no Outliers\n",
    "            time_step_boxplots(residuals=[base_ape, multiOne_ape, multiAll_ape],\n",
    "                                model_names=[\"Baseline\", \"Multistage One\", \"Multistage All\"],\n",
    "                                  title=\"Absolute Percent Error on {} Test Sequences\".format(dataset.capitalize()),\n",
    "                                  savefig_path=IMAGES_OUTPUT_FOLDER+\"MS APE of {} On {} Test Set no Outliers\".format(title_prefix, dataset), xlab=\"Absolute Percent Error\", showfliers = False)\n",
    "                        # Standard Dev\n",
    "            base_std = get_std(base_resids)\n",
    "            multiOne_std = get_std(multiOne_resids)\n",
    "            multiAll_std = get_std(multiAll_resids)\n",
    "\n",
    "            # MAPE\n",
    "            base_mape = get_mape(base_true, base_pred)\n",
    "            multiOne_mape = get_mape(single_true, multiOne_pred)\n",
    "            multiAll_mape = get_mape(single_true, multiAll_pred)\n",
    "\n",
    "            # MSE\n",
    "            base_mse = get_mse(base_true, base_pred)\n",
    "            multiOne_mse = get_mse(single_true, multiOne_pred)\n",
    "            multiAll_mse = get_mse(single_true, multiAll_pred)\n",
    "\n",
    "            # MAE\n",
    "            base_mae = get_mae(base_true, base_pred)\n",
    "            multiOne_mae = get_mae(single_true, multiOne_pred)\n",
    "            multiAll_mae = get_mae(single_true, multiAll_pred)\n",
    "            \n",
    "            \n",
    "            raw_table = []\n",
    "            raw_table.append([\"Baseline\",round(np.mean(base_resids),3), round(base_std,3), round(base_mape,3), round(base_mse,3), round(base_mae,3)])\n",
    "            raw_table.append([\"Multistage One\",round(np.mean(multiOne_resids),3), round(multiOne_std,3), round(multiOne_mape,3), round(multiOne_mse,3), round(multiOne_mae,3)])\n",
    "            raw_table.append([\"Multistage All\",round(np.mean(multiAll_resids),3), round(multiAll_std,3), round(multiAll_mape,3), round(multiAll_mse,3), round(multiAll_mae,3)])\n",
    "            print(\"\\n================\\nMULTISTAGE\\n===============\\n\")\n",
    "            create_latex_table(raw_table)\n",
    "            print(\"\\n================\\n\")\n",
    "          #####################\n",
    "\n",
    "            # Standard Dev\n",
    "            base_std = get_std(base_resids)\n",
    "            single_std = get_std(single_resids)\n",
    "\n",
    "            # MAPE\n",
    "            base_mape = get_mape(base_true, base_pred)\n",
    "            single_mape = get_mape(single_true, single_pred)\n",
    "\n",
    "            # MSE\n",
    "            base_mse = get_mse(base_true, base_pred)\n",
    "            single_mse = get_mse(single_true, single_pred)\n",
    "\n",
    "            # MAE\n",
    "            base_mae = get_mae(base_true, base_pred)\n",
    "            single_mae = get_mae(single_true, single_pred)\n",
    "\n",
    "            # Table of metrics\n",
    "            table = PrettyTable([\"Model\", \"Mean Resids (Mbps)\", \" Resids std (Mbps)\", \"MAPE\", \"MSE\", \"MAE\"])\n",
    "            table.add_row([\"Baseline\",np.mean(base_resids), base_std, base_mape, base_mse, base_mae])\n",
    "            table.add_row([\"{} Only\".format(dataset),np.mean(single_resids), single_std, single_mape, single_mse, single_mae])\n",
    "            print(\"Residuals of {} Sequences Test Set\".format(dataset))\n",
    "            #print(table)\n",
    "            \n",
    "            # Latex\n",
    "            raw_table = []\n",
    "            raw_table.append([\"Baseline\",round(np.mean(base_resids),3), round(base_std,3), round(base_mape,3), round(base_mse,3), round(base_mae,3)])\n",
    "            raw_table.append([\"{} Only\".format(dataset),round(np.mean(single_resids),3), round(single_std,3), round(single_mape,3), round(single_mse,3), round(single_mae,3)])\n",
    "            create_latex_table(raw_table)\n",
    "\n",
    "    true, pred = import_data(model_name=\"{}_multiOne_classifier\".format(prefix))\n",
    "    true = np.argmax(true, axis=-1)\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    conf_matrix = confusion_matrix(true, pred)\n",
    "    # create a dictionary to map class names\n",
    "    class_names = {0: \"low\", 1: \"medium\", 2: \"high\"}\n",
    "\n",
    "    # map the class names\n",
    "    true_names = [class_names[x] for x in true]\n",
    "    pred_names = [class_names[x] for x in pred]\n",
    "    report = classification_report(true_names, pred_names, labels=[\"low\", \"medium\", \"high\"])\n",
    "    print(\"Classification Report:\\n\",report)\n",
    "    display_conf = ConfusionMatrixDisplay(conf_matrix, display_labels=[\"Low\", \"Medium\", \"High\"])\n",
    "    display_conf.plot(cmap=\"Oranges\")\n",
    "    plt.savefig(IMAGES_OUTPUT_FOLDER+\"{} Confusion Matrix\".format(title_prefix), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(\"constraint_1_5\", \"Size Constraint of 1 and a half MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(\"constraint_3\", \"Constraint 3Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(\"univariate\", \"Univariate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carry_out_analysis(\"Multivariate\", \"Multivariate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Error Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(model_name=\"univariate_multiAll_classifier\")\n",
    "x = np.load(TEST_FOLDER+\"univariate_test_x.npy\").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(x, true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = import_data(model_name=\"univariate_multiAll_classifier\")\n",
    "true = np.argmax(true, axis=-1)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "conf_matrix = confusion_matrix(true, pred)\n",
    "# create a dictionary to map class names\n",
    "class_names = {0: \"low\", 1: \"medium\", 2: \"high\"}\n",
    "# map the class names\n",
    "true_names = [class_names[x] for x in true]\n",
    "pred_names = [class_names[x] for x in pred]\n",
    "report = classification_report(true_names, pred_names, labels=[\"low\", \"medium\", \"high\"])\n",
    "print(\"Classification Report:\\n\",report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"C:/Users/Killian/Desktop/FYP-Multistage-Throughput-Predictor/Datasets/Testing/univariate_classifier_test_x.npy\")\n",
    "y = np.load(\"C:/Users/Killian/Desktop/FYP-Multistage-Throughput-Predictor/Datasets/Testing/univariate_test_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"true\"] = true_names\n",
    "df[\"pred\"] = pred_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_as_med = df[(df[\"true\"]==\"low\") & (df[\"pred\"]==\"medium\")].index.to_list()\n",
    "med_as_low = df[(df[\"true\"]==\"medium\") & (df[\"pred\"]==\"low\")].index.to_list()\n",
    "low_med_boundary = low_as_med + med_as_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_low_med_boundary = y[low_med_boundary,:]\n",
    "tp_low_med_boundary = tp_low_med_boundary/1024\n",
    "low_med_bound_means = np.mean(tp_low_med_boundary, axis=1)\n",
    "low_med_bound_std = np.std(tp_low_med_boundary, axis=1)\n",
    "mean_val = [np.mean(low_med_bound_means)]*(low_med_bound_means.shape[0])\n",
    "plt.plot(low_med_bound_means)\n",
    "plt.plot(mean_val, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = [np.mean(low_med_bound_means)]*(low_med_bound_means.shape[0])\n",
    "plt.plot(low_med_bound_means)\n",
    "plt.plot(mean_val, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(low_med_bound_means)\n",
    "plt.plot(mean_val, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bound = y[low_as_med,:]/1024\n",
    "low_mean = np.mean(low_bound)\n",
    "low_std = np.std(low_bound)\n",
    "mean_vector = [low_mean]*low_bound.shape[0]\n",
    "std_vector = [low_std]*low_bound.shape[0]\n",
    "std_vector_up = [low_std+low_mean]*low_bound.shape[0]\n",
    "std_vector_down = [low_mean-low_std]*low_bound.shape[0]\n",
    "plt.ylim(0,1.4)\n",
    "plt.plot([1]*low_bound.shape[0], linestyle=\"-\", color=\"blue\")\n",
    "plt.plot(mean_vector, color=\"red\")\n",
    "plt.plot(std_vector_up, linestyle=\"--\", color=\"red\")\n",
    "plt.plot(std_vector_down, linestyle=\"--\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_bound = y[med_as_low,:]/1024\n",
    "med_mean = np.mean(med_bound)\n",
    "med_std = np.std(med_bound)\n",
    "mean_vector = [med_mean]*med_bound.shape[0]\n",
    "std_vector = [med_std]*med_bound.shape[0]\n",
    "std_vector_up = [med_std+med_mean]*med_bound.shape[0]\n",
    "std_vector_down = [med_mean-med_std]*med_bound.shape[0]\n",
    "#plt.ylim(0,1.4)\n",
    "plt.plot([1]*med_bound.shape[0], linestyle=\"-\", color=\"blue\")\n",
    "plt.plot(mean_vector, color=\"red\")\n",
    "plt.plot(std_vector_up, linestyle=\"--\", color=\"red\")\n",
    "plt.plot(std_vector_down, linestyle=\"--\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0f0acd0089a531616946ee2a9708cd6d3e1ac7fcc3f79f44e37592fb92385f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
